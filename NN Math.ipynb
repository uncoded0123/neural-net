{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e3a158a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "1.4399999999999984\n",
      "0.05759999999999925\n",
      "0.0023039999999998335\n",
      "9.21599999999797e-05\n",
      "3.686399999993731e-06\n",
      "1.4745600000029495e-07\n",
      "5.898239999793519e-09\n",
      "2.3592959996991286e-10\n",
      "9.437183990065367e-12\n"
     ]
    }
   ],
   "source": [
    "def f(x,w):\n",
    "    return x*w\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def loss(x,y):\n",
    "    return (x - y)**2\n",
    "\n",
    "x = 2\n",
    "w = 7\n",
    "y = 20\n",
    "\n",
    "for i in range(10):\n",
    "    l1 = f(x,w)\n",
    "    a1 = relu(l1)\n",
    "    loss1 = loss(a1,y)\n",
    "    print(loss1)\n",
    "\n",
    "    dloss1_da1 = 2 * (a1 - y)\n",
    "    da1_dl1 = 1 if l1>=0 else 0\n",
    "    dl1_dw = x\n",
    "    dloss1_dw = dloss1_da1 * da1_dl1 * dl1_dw\n",
    "\n",
    "    w = w - 0.1 * dloss1_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd09139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([200, 197, 197,  ..., 108, 113, 118], dtype=torch.uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "im = np.array(Image.open('cat.jpg').convert('L'))\n",
    "x = torch.tensor(im).flatten()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a82f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "340a52ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000000774144\n",
      "20.000001548288\n",
      "20.000001548288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.397195733789053e-12"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(w)\n",
    "w = w - 0.1 * dloss1_dw\n",
    "print(w)\n",
    "l1 = f(x,w)\n",
    "print(l1)\n",
    "a1 = relu(l1)\n",
    "print(a1)\n",
    "loss1 = loss(a1,y)\n",
    "\n",
    "\n",
    "dloss1_da1 = 2 * (a1 - y)\n",
    "da1_dl1 = 1 if l1>0 else 0\n",
    "dl1_dw = x\n",
    "\n",
    "dloss1_dw = dloss1_da1 * da1_dl1 * dl1_dw\n",
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef24f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9492dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.00039999993055"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad check\n",
    "def f(x,w):\n",
    "    return x*w\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def loss(x,y):\n",
    "    return (x - y)**2\n",
    "\n",
    "x = 2\n",
    "w = 7\n",
    "y = 3\n",
    "\n",
    "l1 = f(x,w)\n",
    "a1 = relu(l1)\n",
    "loss1 = loss(a1,y)\n",
    "\n",
    "h = 0.0001\n",
    "\n",
    "# dloss1_da1 = (loss(a1+h, y) - loss(a1, y)) / h\n",
    "# drelu_dl1 = (relu(l1+h) - relu(l1)) / h\n",
    "# dl1_dw = (f(x,w+h) - f(x,w)) / h\n",
    "\n",
    "loss1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# grad check\n",
    "def f(x,w):\n",
    "    return x*w\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def loss(x,y):\n",
    "    return (x - y)**2\n",
    "\n",
    "x = 2\n",
    "w = 7\n",
    "y = 3\n",
    "\n",
    "l1 = f(x,w+h)\n",
    "a1 = relu(l1)\n",
    "loss1 = loss(a1,y)\n",
    "\n",
    "h = 0.0001\n",
    "\n",
    "# dloss1_da1 = (loss(a1+h, y) - loss(a1, y)) / h\n",
    "# drelu_dl1 = (relu(l1+h) - relu(l1)) / h\n",
    "# dl1_dw = (f(x,w+h) - f(x,w)) / h\n",
    "\n",
    "(loss1 - loss1111) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b1fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205df95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.        ,  7.05620956]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFNN Python\n",
    "import math\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = np.random.randn(n_in, n_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.inputs = x\n",
    "        self.output = inputs * self.w\n",
    "\n",
    "    def backward(self, x):\n",
    "        self.dw = self.inputs\n",
    "        \n",
    "#############################\n",
    "\n",
    "class ActivationReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.maximum(0, inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        self.drelu = np.where(self.inputs>0, 1, 0)\n",
    "\n",
    "        \n",
    "class SqErrLoss:\n",
    "    def forward(self, y_hat, y):\n",
    "         return (y_hat - y)**2\n",
    "\n",
    "    def backward(self, y_hat):\n",
    "        self.dy_hat = 2 * (y_hat - y)\n",
    "\n",
    "        \n",
    "x = np.array([-1,2])\n",
    "y = np.array([1,0])\n",
    "\n",
    "nn = NN(1,1)\n",
    "loss = Loss()\n",
    "\n",
    "\n",
    "l1 = nn.linear(x)\n",
    "y_hat = nn.ReLU(l1)\n",
    "sqe_loss = loss.squared_error(y_hat, y)\n",
    "\n",
    "dl1_dw = nn.linear(x, grad_wrt='w')[1]\n",
    "drelu_dx = nn.linear(x, grad_wrt='x')[1]\n",
    "dsqe_loss_drelu = loss.squared_error(y_hat, y, grad_wrt='y_hat')\n",
    "dsqe_loss_drelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae46bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8687db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f2581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.002471659200743"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss, Categorical Cross Entropy\n",
    "# Python\n",
    "def categorical_cross_entropy(probabilities):\n",
    "    import math\n",
    "    \n",
    "    y = [1,0]\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(len(y)):\n",
    "        loss -= y[i] * math.log(probabilities[i])\n",
    "    \n",
    "    return loss\n",
    "\n",
    "categorical_cross_entropy(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f55dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90c63f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.80485139e-35, 1.00000000e+00])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFNN numpy\n",
    "import numpy as np\n",
    "\n",
    "def f(w,x):\n",
    "    return w * x\n",
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.e**x / np.sum(np.e**x)\n",
    "\n",
    "xs = np.array([-1,2])\n",
    "ws = np.array([4,5])\n",
    "ws2 = np.array([7,8])\n",
    "\n",
    "l1 = f(ws,xs)\n",
    "act1 = ReLU(l1)\n",
    "l2 = f(ws2, act1)\n",
    "probabilities = softmax(l2)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e036b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss, Categorical Cross Entropy\n",
    "# numpy\n",
    "import numpy as np\n",
    "y = np.array([1,0])\n",
    "-np.log(np.sum(probabilities * y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdb008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f8eb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8049e-35, 1.0000e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFNN pytorch\n",
    "\n",
    "import torch\n",
    "\n",
    "def f(w,x):\n",
    "    return w * x\n",
    "\n",
    "def ReLU(x):\n",
    "    return torch.relu(x)\n",
    "\n",
    "def softmax(x):\n",
    "    return torch.e**x / torch.sum(torch.e**x)\n",
    "\n",
    "xs = torch.tensor([-1,2])\n",
    "ws = torch.tensor([4,5])\n",
    "ws2 = torch.tensor([7,8])\n",
    "\n",
    "l1 = f(ws,xs)\n",
    "act1 = ReLU(l1)\n",
    "l2 = f(ws2, act1)\n",
    "logits = l2\n",
    "probabilities = softmax(logits)\n",
    "probabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
